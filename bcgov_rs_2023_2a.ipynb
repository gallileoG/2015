{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gallileoG/2015/blob/master/bcgov_rs_2023_2a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rasters\n",
        "###### bcgov-rs-workshop-2023"
      ],
      "metadata": {
        "id": "CFrupUyz7lOf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will look at ways to load, analyze, and display rasters using Python."
      ],
      "metadata": {
        "id": "Ahkl6AAXFQNE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "ZS4iLY8aDrA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll start by installing a few additional modules to our environment that we'll use later. Custom environments do not persist between Google Colab sessions, so you will need to install these dependencies each time you start/restart the runtime."
      ],
      "metadata": {
        "id": "1nwaT6MKHS8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "K9wz7AK48ArJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all the necessary dependencies."
      ],
      "metadata": {
        "id": "m4si33mnJA3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "\n",
        "from PIL import Image, ImageFilter\n",
        "\n",
        "import rasterio\n",
        "from rasterio.warp import calculate_default_transform, reproject, Resampling"
      ],
      "metadata": {
        "id": "BiUjhmiR9L6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nonspatial Rasters (numpy)"
      ],
      "metadata": {
        "id": "Tqy_HR-HiXwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rasters are sometimes called \"grids\" for good reason: they are literally grids of values (usually integers or floating values [decimals]). The standard Python data structures for gridded numeric data are [numpy arrays](https://numpy.org/doc/stable/reference/arrays.html).\n",
        "\n",
        "Numpy arrays have a defined `shape`, consisting of sizes of each dimension. For example, a 2D array has two dimensions: `[rows, columns]` (note the order). Here, we define a `[2, 2]` numpy array from a list of lists of numbers:"
      ],
      "metadata": {
        "id": "GXhhCCjTJQHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vals = [\n",
        "    [1, 2],\n",
        "    [3, 4]\n",
        "]\n",
        "\n",
        "arr = np.array(vals)\n",
        "arr"
      ],
      "metadata": {
        "id": "gbUs1bb78E1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also instantiate a random numpy array of any shape:"
      ],
      "metadata": {
        "id": "bJXRQ94c8ftx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.random.randint(low=0, high=256, size=[3,4])\n",
        "print(arr)"
      ],
      "metadata": {
        "id": "xxqdGE9fFI7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other useful array generation methods are:\n",
        "- [np.ones()](https://numpy.org/doc/stable/reference/generated/numpy.ones.html)\n",
        "- [np.zeros()](https://numpy.org/doc/stable/reference/generated/numpy.zeros.html)\n",
        "- [np.arange()](https://numpy.org/doc/stable/reference/generated/numpy.arange.html)\n",
        "  - note that arange will create an array on a single row, so it is often followed by [reshape()](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html#)"
      ],
      "metadata": {
        "id": "dp4hQ0zI83Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr_ones = np.ones([2, 2])\n",
        "arr_zeros = np.zeros([2, 2])\n",
        "arr_arange = np.arange(9).reshape([3, 3])\n",
        "\n",
        "print(f\"arr_ones: \\n{arr_ones}\")\n",
        "print(f\"arr_zeros: \\n{arr_zeros}\")\n",
        "print(f\"arr_arange: \\n{arr_arange}\")"
      ],
      "metadata": {
        "id": "q4uNknKk9dOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition to holding gridded numeric values, numpy arrays have properties:\n",
        "- `shape`: a 2D array (a flat table) has a shape like `[rows, columns]` (note the order), where each index of row/column holds a pixel value. We will also see 3D arrays, which often either have a shape like `[row, column, band]` or `[band, row, column]`, depending on the needs of the module we intend to use. Be aware that numpy arrays can have more dimensions, as well.\n",
        "- `dtype`: this is the data type of the values in the arrays. Each array has only one data type. Data type corresponds to pixel bit depth. Numpy has numerous built-in [data types](https://numpy.org/doc/stable/reference/arrays.scalars.html#sized-aliases). We will most often encounter `np.uint8` (unsigned 8-bit integers [0 - 255]).\n",
        "- `size`: the number of elements in an array\n",
        "- `ndim`: the number of dimensions in an array\n",
        "- `nbytes`: the number of bytes of the array\n",
        "- numerous summary statistics are available, as well, such as `np.mean()` shown below"
      ],
      "metadata": {
        "id": "Zq832f8fKglW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(arr)\n",
        "print(f\"Shape: {arr.shape}\")\n",
        "print(f\"Data Type: {arr.dtype}\")\n",
        "print(f\"Size: {arr.size}\")\n",
        "print(f\"Number of Dimensions: {arr.ndim}\")\n",
        "print(f\"Array Mean: {np.mean(arr)}\")\n",
        "print(f\"Number of Bytes: {arr.nbytes}\")"
      ],
      "metadata": {
        "id": "Fkozv8mQKgAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that our array was created as dtype = int64 (signed 64-bit) by default, and occupies 96 bytes. 1 byte = 8 bits. 64 bits = 8 bytes. There are twelve 8-byte values in our array.\n",
        "\n",
        "When we created the array, we specified that we wanted integer values in the range 0 - 255, which can fit into the `np.uint8` data type. We can change the dtype using the `astype` method. Notice how much space we save simply by choosing the minimum necessary data type. Saving a few bytes here and there is not very important in this context, but at scale can be a huge savings."
      ],
      "metadata": {
        "id": "PIzetoKn_V-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr8 = arr.astype(np.uint8)\n",
        "print(arr8)\n",
        "print(f\"Shape: {arr8.shape}\")\n",
        "print(f\"Data Type: {arr8.dtype}\")\n",
        "print(f\"Size: {arr8.size}\")\n",
        "print(f\"Number of Dimensions: {arr8.ndim}\")\n",
        "print(f\"Array Mean: {np.mean(arr8)}\")\n",
        "print(f\"Number of Bytes: {arr8.nbytes}\")"
      ],
      "metadata": {
        "id": "n616eE_H_zX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can display 2D arrays using matplotlib. Notice that values close to 0 are black, and those close to 255 are white. Try changing the `size` parameter to create more pixels in the array (e.g. `size=[300, 400]`). Also notice that we can control the dtype during array creation."
      ],
      "metadata": {
        "id": "6Xwgr4Ll-p7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.random.randint(low=0, high=256, size=[3,4], dtype=np.uint8)\n",
        "print(arr, arr.dtype)\n",
        "plt.imshow(arr, cmap=\"gray\")"
      ],
      "metadata": {
        "id": "4-GC52-Fjv1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also create multiband rasters with numpy. These rasters take the shape of `[rows, columns, bands]`. In the example below, we create an array with the shape `[5, 4, 3]`, resulting in an image with 5 rows, 4 columns, and 3 bands. 3-band rasters are common in remote sensing data, because they are easily displayed as color images by assigning one band each to correspond to the colors red, green, and blue (\"RGB\" images). Matplotlib automatically displays 3-band images as RGB. Notice that pixels correspond to RGB values (e.g. an array value of `[255, 0, 0]` would result in a pixel that appears very red). Try entering some of the RGB values into an [RGB Calculator](https://www.w3schools.com/colors/colors_rgb.asp) to convince yourself that numpy and matplotlib are working together to display our numeric values as colored pixels."
      ],
      "metadata": {
        "id": "bU5XwLgfDUWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.random.randint(low=0, high=256, size=[5,4,3], dtype=np.uint8)\n",
        "print(arr, arr.dtype)\n",
        "plt.imshow(arr)"
      ],
      "metadata": {
        "id": "n1QlZPqtCl6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can reference pixel values by indices (recall that Python indices are 0-based):\n",
        "\n",
        "- `arr[0, 2, 1]`: reference the value in the first row, third column, and second band\n",
        "\n",
        "We can also reference \"slices\" of data, using [slice notation](https://numpy.org/doc/stable/user/basics.indexing.html#slicing-and-striding).\n",
        "\n",
        "- `arr[0, 0, :]`: first row, first column, all band values\n",
        "- `arr[:2, :2, :]`: first two rows, first two columns, all band values\n",
        "- `arr[1:3, :3, :]`: rows 2-3, first three columns, all band values \n",
        "\n",
        "Try referencing specific pixel values and slices of pixels."
      ],
      "metadata": {
        "id": "ZQEcFIJkGIsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_pixels = arr[1:3, :3, :]\n",
        "plt.imshow(selected_pixels)"
      ],
      "metadata": {
        "id": "2pqzJiMVDEoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nonspatial Rasters (pillow)"
      ],
      "metadata": {
        "id": "clWx5h15D877"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, we've generated image data ourselves, but usually we will read a file or retrieve image data from an API.\n",
        "\n",
        "The main module for reading nonspatial imagery is [pillow](https://pillow.readthedocs.io/en/stable/) (derived from \"PIL\": the Python Imaging Library). We can instantiate an `Image` object with `Image.open()` - we can open image files (e.g. jpeg, png, etc.) or load raw image data from an API like below. Below, we retrieve an image from [cataas](https://cataas.com/#/) (\"Cat As A Service\").\n",
        "\n",
        "Note that the URL ends with a specific ID, meaning that we will retrieve a specific image. You can omit the ID to retrieve a random cat image, however, there is no guarantee that all images will work nicely in later cells (i.e. they may have a different number of dimensions)."
      ],
      "metadata": {
        "id": "S-B-piOb005o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://cataas.com/cat/g9ECV9Q1e9nciaoY\"\n",
        "\n",
        "im = Image.open(requests.get(url, stream=True).raw)\n",
        "im"
      ],
      "metadata": {
        "id": "bGeww0IYw2mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can load the PIL image object to a numpy array:"
      ],
      "metadata": {
        "id": "wnN_rFuY2Z1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array(im)\n",
        "arr"
      ],
      "metadata": {
        "id": "ua8xgbe6ykvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And print out common numpy array metadata:"
      ],
      "metadata": {
        "id": "Md5nPK6Y20tV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape: {arr.shape}\")\n",
        "print(f\"Data Type: {arr.dtype}\")\n",
        "print(f\"Size: {arr.size}\")\n",
        "print(f\"Number of Dimensions: {arr.ndim}\")\n",
        "print(f\"Array Mean: {np.mean(arr)}\")\n",
        "print(f\"Number of Bytes: {arr.nbytes}\")"
      ],
      "metadata": {
        "id": "xCHV2ZSe26ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And extract and slice pixels as we have already seen. Here, we show each band separately. Notice that \"red\" pixels are relatively high (white) in the red band, and similar for other colours. Note this method for displaying multiple outputs."
      ],
      "metadata": {
        "id": "JMZGeEZT3JUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(arr[:, :, 0], cmap=\"gray\")\n",
        "plt.title('Red Channel')\n",
        "plt.show()\n",
        "plt.imshow(arr[:, :, 1], cmap=\"gray\")\n",
        "plt.title('Green Channel')\n",
        "plt.show()\n",
        "plt.imshow(arr[:, :, 2], cmap=\"gray\")\n",
        "plt.title('Blue Channel')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o2Pi4QdQ3O_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`pillow` has lots of image processing functionality that we won't cover in this workshop, but we will take a quick look at [ImageFilters](https://pillow.readthedocs.io/en/stable/reference/ImageFilter.html).\n",
        "\n",
        "There are several built-in image filters that we can see below. You can chain the output of one filter into another filter. For example, you could first blur an image and then extract visual contours for a rudimentary object detection algorithm.\n",
        "\n",
        "Below, we resize the original image just to limit the size of the output. It's not strictly necessary.\n",
        "\n",
        "Note another method for displaying multiple outputs."
      ],
      "metadata": {
        "id": "X7osRVQm-8Lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scale_factor = 0.5\n",
        "small_im = im.resize(\n",
        "    (\n",
        "      int(im.width * scale_factor), int(im.height * scale_factor)\n",
        "    )\n",
        "  )\n",
        "\n",
        "im1 = small_im.filter(ImageFilter.BLUR)\n",
        "im2 = small_im.filter(ImageFilter.CONTOUR)\n",
        "im3 = small_im.filter(ImageFilter.DETAIL)\n",
        "im4 = small_im.filter(ImageFilter.EDGE_ENHANCE)\n",
        "im5 = small_im.filter(ImageFilter.EDGE_ENHANCE_MORE)\n",
        "im6 = small_im.filter(ImageFilter.EMBOSS)\n",
        "im7 = small_im.filter(ImageFilter.FIND_EDGES)\n",
        "im8 = small_im.filter(ImageFilter.SHARPEN)\n",
        "im9 = small_im.filter(ImageFilter.SMOOTH)\n",
        "im10 = small_im.filter(ImageFilter.SMOOTH_MORE)\n",
        "\n",
        "display(\n",
        "    im1,\n",
        "    im2,\n",
        "    im3,\n",
        "    im4,\n",
        "    im5,\n",
        "    im6,\n",
        "    im7,\n",
        "    im8,\n",
        "    im9,\n",
        "    im10\n",
        ")"
      ],
      "metadata": {
        "id": "C4uWi34M_a9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spatial Rasters (rasterio)"
      ],
      "metadata": {
        "id": "jZkcwLAfib--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The previous sections have shown us how to create and load nonspatial images, but most remote sensing images are spatial. We want to make measurements and show them on maps!\n",
        "\n",
        "Let's start by collecting a spatial image. The link below is from [BC Map & Orthos](https://a100.gov.bc.ca/ext/mtec/public/products/mapsheet). You can use the provided link, or find your own by:\n",
        "- navigate to [BC Map & Orthos](https://a100.gov.bc.ca/ext/mtec/public/products/mapsheet)\n",
        "- select a mapsheet on the map (make note of the mapsheet name)\n",
        "- on the `NTS 250K` tab, under the `Raster Topographic Maps (NTS)` section, right-click and copy the link for the `BC Albers TIFF` download button.\n",
        "\n",
        "The download function will save the topographic map delivery zipfile to this Google Colab session data. Check the `Files` (folder icon) on the lefthand side of the screen. You will likely have `refresh` the view, as well."
      ],
      "metadata": {
        "id": "8B1v2nQ0VXnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_url(url, save_path, chunk_size=128):\n",
        "    r = requests.get(url, stream=True)\n",
        "    with open(save_path, 'wb') as fd:\n",
        "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "            fd.write(chunk)\n",
        "\n",
        "url = \"https://pub.data.gov.bc.ca/datasets/177864/tif/bcalb/093n/bc_093n_xc10m_bcalb.zip\"\n",
        "zip_path = \"bcalb.zip\"\n",
        "download_url(url, zip_path)"
      ],
      "metadata": {
        "id": "dVFsGn6DV2Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Rasterio](https://rasterio.readthedocs.io/en/latest/) is the most common Python module for spatial raster data. In addition to handling imagery in a similar way to how we have already seen `numpy` and `pillow` do it, `rasterio` handles the spatial aspect of our data.\n",
        "\n",
        "If you've downloaded your own image above, be sure to update the `mapsheet` variable so the contained tiff file can be found.\n",
        "\n",
        "We load imagery with rasterio using `rasterio.open()`. We usually point it directly to a `.tif` (or `.tiff`) file or url, but in this case we have a local zipfile containing a `.tif`. Luckily, there is [support for that](https://rasterio.readthedocs.io/en/latest/topics/datasets.html#dataset-identifiers). The main thing to note is the syntax: `'zip:///path/to/file.zip!/folder/file.tif'`\n",
        "\n",
        "Once opened, pay attention to the `profile`. This is where all of the dataset's spatial metadata is found. Note that there is information about the data type, image dimensions, number of bands (\"count\"), and coordinate reference system (\"crs\"). Also, note that we retrieved this metadata very quickly - we have not read any pixel values yet, only retrieved metadata about the dataset as a whole.\n"
      ],
      "metadata": {
        "id": "HYPXOzJTBEwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mapsheet = \"093N\"\n",
        "tif_path = f\"zip://{zip_path}!/{mapsheet}.tif\"\n",
        "\n",
        "dataset = rasterio.open(tif_path)\n",
        "dataset.profile"
      ],
      "metadata": {
        "id": "PBa7OjivVWRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can read actual pixel values with the `read()` method. Note that band indexing starts at 1 - you will retrieve an error if you attempt `dataset.read(0)`. Also, observe that the result of reading pixel values is our good friend, numpy array!"
      ],
      "metadata": {
        "id": "WNyFC6dFMqDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "band1 = dataset.read(1)\n",
        "band1"
      ],
      "metadata": {
        "id": "qUVDQ34IvN8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now you can display it, or use in any other way that you have learned to use numpy arrays."
      ],
      "metadata": {
        "id": "pQ1fGRIANGCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(band1)"
      ],
      "metadata": {
        "id": "5M6ytiTJvQqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can read individual bands and combine into a multiband numpy array with [np.dstack()](https://numpy.org/doc/stable/reference/generated/numpy.dstack.html). Note that the array shape correspond to the dataset profile values: `[height, width, count]`"
      ],
      "metadata": {
        "id": "LGQo0-OUNQcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Profile: {dataset.profile}\")\n",
        "r = dataset.read(1)\n",
        "g = dataset.read(2)\n",
        "b = dataset.read(3)\n",
        "band_stack = np.dstack([r, g, b])\n",
        "print(f\"Array Shape: {band_stack.shape}\")\n",
        "\n",
        "plt.imshow(band_stack)"
      ],
      "metadata": {
        "id": "MVJ9f5bPvrYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can slice our multiband array as we have seen before:"
      ],
      "metadata": {
        "id": "MoJfwnaJNmnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(band_stack[500:1500, 3500:4500, :])"
      ],
      "metadata": {
        "id": "KE41J0M5v6Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our next goal will be to display this image correctly geolocated on a `folium` map. We will create a Raster Layer ImageOverlay (https://python-visualization.github.io/folium/modules.html#module-folium.raster_layers), which requires the image array, plus bounding box coordinates *in latitude/longitude* (EPSG:4326). You may have noticed our image was provided in BC Albers (EPSG:3005):"
      ],
      "metadata": {
        "id": "4E7OB_JREIe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Profile: {dataset.profile}\")\n",
        "print(f\"CRS: {dataset.crs}\")"
      ],
      "metadata": {
        "id": "U9tIOxUVFFAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we print the bounds of the original image, the coordinates will be in BC Albers:"
      ],
      "metadata": {
        "id": "EwntZc0bFSMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"BBox: {dataset.bounds}\")"
      ],
      "metadata": {
        "id": "LlPFVR3AFZUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to get lat/long coordinates, we must* reproject our original image and use the bounds from the reprojected image. Rasterio provides a method for [reprojecting images](https://rasterio.readthedocs.io/en/latest/topics/reproject.html). We will save a new file called `reprojected.tif` in the session storage.\n",
        "\n",
        "*in some cases, it may also work to reproject only the corner coordinates, but for this demonstration we will reproject the entire image."
      ],
      "metadata": {
        "id": "lucMNFknFfNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dst_crs = 'EPSG:4326'\n",
        "\n",
        "transform, width, height = calculate_default_transform(\n",
        "    dataset.crs, dst_crs, dataset.width, dataset.height, *dataset.bounds)\n",
        "kwargs = dataset.meta.copy()\n",
        "kwargs.update({\n",
        "    'crs': dst_crs,\n",
        "    'transform': transform,\n",
        "    'width': width,\n",
        "    'height': height\n",
        "})\n",
        "\n",
        "with rasterio.open('reprojected.tif', 'w', **kwargs) as dst:\n",
        "    for i in range(1, dataset.count + 1):\n",
        "        reproject(\n",
        "            source=rasterio.band(dataset, i),\n",
        "            destination=rasterio.band(dst, i),\n",
        "            src_transform=dataset.transform,\n",
        "            src_crs=dataset.crs,\n",
        "            dst_transform=transform,\n",
        "            dst_crs=dst_crs,\n",
        "            resampling=Resampling.nearest)"
      ],
      "metadata": {
        "id": "Vn1AHr-QwR6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the new file into a rasterio dataset object:"
      ],
      "metadata": {
        "id": "PtQC2RlCG17B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reprojected_dataset = rasterio.open('reprojected.tif')\n",
        "reprojected_dataset.profile"
      ],
      "metadata": {
        "id": "BcoduVzCO4bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can read each data band into a numpy array, and combine the individual bands into an RGB composite using np.dstack()."
      ],
      "metadata": {
        "id": "Bzh9eyZEG8Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = reprojected_dataset.read(1)\n",
        "g = reprojected_dataset.read(2)\n",
        "b = reprojected_dataset.read(3)\n",
        "band_stack = np.dstack([r, g, b])\n",
        "band_stack.shape\n",
        "\n",
        "plt.imshow(band_stack)"
      ],
      "metadata": {
        "id": "sOfh_6ZJQg8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And also notice that the dataset bounds are reported in coordinates of lat/long:"
      ],
      "metadata": {
        "id": "4QMlbFtPHSKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reprojected_dataset.bounds"
      ],
      "metadata": {
        "id": "KHs6HtRrQ9Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can create a folium map, assemble the bounds coordinates, and create an ImageOverlay:"
      ],
      "metadata": {
        "id": "1_PgJSApHcSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = folium.Map(location=[54.361, -124.885], zoom_start=5)\n",
        "\n",
        "bounds = [\n",
        "    [reprojected_dataset.bounds.bottom, reprojected_dataset.bounds.left],\n",
        "    [reprojected_dataset.bounds.top, reprojected_dataset.bounds.right]\n",
        "]\n",
        "folium.raster_layers.ImageOverlay(band_stack, bounds, pixelated=False).add_to(m)\n",
        "\n",
        "folium.LayerControl().add_to(m)\n",
        "m"
      ],
      "metadata": {
        "id": "i-sUSM2_PEM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Credit Ideas\n",
        "\n",
        "- explore [LidarBC](https://www2.gov.bc.ca/gov/content/data/geographic-data-services/lidarbc)\n",
        "  - download a DEM tif (not laz file) and upload to this notebook\n",
        "  - open the image using rasterio\n",
        "  - inspect the metadata\n",
        "  - display the image\n",
        "  - try to display values only above or below certain values\n",
        "  - try extracting vector features (lines) delineating values at a certain elevation (see [here](https://rasterio.readthedocs.io/en/latest/topics/features.html))\n",
        "  - display the DEM on a folium map\n",
        "  - if you extracted features above, try to display them on a folium map\n",
        "- look for an image (.tif) in the [Canada SPOT Orthoimages STAC Catalog](https://stacindex.org/catalogs/spot-orthoimages-canada-2005#/). We will discuss STAC more in the next session, but you can click links to drill deeper into the catalog until you find images under the \"Assets\" tab in the associated item.\n",
        "  - download the image and upload to this notebook\n",
        "  - read with raterio\n",
        "  - manipulate in numpy as you please\n",
        "  - display on a folium map\n",
        "- explore [numpy](https://numpy.org/) (this could be a whole workshop)\n",
        "  - poke around in the [reference](https://numpy.org/doc/stable/reference/index.html#reference) just to see how many functions are available\n",
        "  - [X-ray image processing tutorial](https://numpy.org/numpy-tutorials/content/tutorial-x-ray-image-processing.html)\n",
        "- explore [pillow](https://pillow.readthedocs.io/en/stable/)\n",
        "  - [tutorial](https://pillow.readthedocs.io/en/stable/handbook/tutorial.html)\n",
        "- there is another common nonspatial image module that we will not cover in this workshop: [OpenCV](https://docs.opencv.org/4.x/). OpenCV is similar to pillow, but with a computer vision (CV) focus. Google Colab notebooks are preloaded with OpenCV.\n",
        "  - [OpenCV Python tutorials](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html)\n",
        "  - I find the OpenCV documentation/tutorials quite difficult to parse, so often turn to external resources, like:\n",
        "    - [PyImageSearch](https://pyimagesearch.com/start-here/)\n",
        "    - [LearnOpenCV](https://learnopencv.com/getting-started-with-opencv/)\n",
        "- "
      ],
      "metadata": {
        "id": "VxVCgp6eh5Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WC9Vm92K4Jsc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}